Twitter Sentiment Analysis Using NLTK
This project demonstrates how to build a sentiment analysis model using the Natural Language Toolkit (NLTK) in Python. The model is trained on a dataset of tweets labeled as Positive, Negative, or Neutral. It focuses on classifying tweets into Positive or Negative sentiments using a Naive Bayes classifier.

Key Features
Loads and processes labeled tweet data from a CSV file.

Removes neutral sentiments to focus on binary classification (Positive/Negative).

Prepares and extracts features for model training using NLTK.

Trains a Naive Bayes classifier with the extracted features.

Tests the model on a sample set and prints accuracy statistics for positive and negative predictions.

Includes tools like WordCloud and Matplotlib for data visualization.

Technologies Used
Python

Pandas for data loading and manipulation

NLTK for text processing and model training

Scikit-learn for train/test splitting

Matplotlib and WordCloud for optional visualizations

Dataset
The dataset used (Sentiment.csv) contains two columns:

text: The tweet content

sentiment: The sentiment label (Positive, Negative, or Neutral)

How It Works
Load and clean the dataset.

Remove neutral sentiments to simplify the task to binary classification.

Split data into training and test sets.

Extract features from the tweets using a custom extract_features() function (you'll need to define this).

Train the Naive Bayes classifier on the training set.

Evaluate the classifier's performance on test samples.
